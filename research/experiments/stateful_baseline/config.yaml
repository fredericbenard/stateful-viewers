# Experiment: Stateful baseline v2
#
# Tests the v2 prompt architecture (profile + style + initial state + reflection)
# with factored dimensions. Unlike the emotional_response experiment, this is a
# multi-stage pipeline: profile, style, and initial state are generated first
# (text-only LLM), then the reflection prompt is sent with an image (VLM).
#
# The current eval_pipeline runner handles single-stage (prompt + image) calls.
# This config defines the VLM stage (reflection); the text-only stages are
# documented in prompts.yaml and can be run manually or via an extended runner.

experiment_id: stateful_baseline

# Provider and model for the reflection (VLM) stage.
# Profile/style/state generation may use a different (text-only) model.
provider: openai
model: gpt-5.2

temperature: 0.7
max_tokens: 2048

# Images to use. Replace or extend with your own.
images:
  - id: bellechasse
    source: "https://fredericbenard.com/images/digital/galleries/new_work/full/2025_06__dscf3326.jpg"
    caption: "Centre de transport Bellechasse, 7000 Bellechasse St, Montreal, Quebec, 2025"

# For a sequential gallery walk, add multiple images in order:
#  - id: image_02
#    source: "..."
#  - id: image_03
#    source: "..."

# Prompt variant ids to run (empty = all). Since this experiment uses a
# template-based prompt (not flat variants), this field is not used by the
# current runner. It is reserved for future multi-stage runner support.
prompt_variant_ids: []
